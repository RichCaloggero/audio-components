<!doctype html><html><head><title>Audio Components</title></head> 
<h1 id="audio-components">Audio Components</h1>
<p>This project was begun as a way to learn Polymer.</p>
<h2 id="installation">Installation</h2>
<ul>
<li>download via git clone or equivalent</li>
<li>navigate to root folder and open command prompt</li>
<li>install polymer if not already installed<ul>
<li>npm install -g polymer-cli</li>
</ul>
</li>
<li>install bower<ul>
<li>npm install -g bower</li>
</ul>
</li>
<li>install polymer runtime<ul>
<li>bower install</li>
</ul>
</li>
<li>run polymer server<ul>
<li>polymer serve</li>
</ul>
</li>
<li>click the <code>run-demo.bat</code> file in root folder or open browser to <code>localhost:8081/demo/</code></li>
</ul>
<h2 id="elements">Elements</h2>
<p>The package contains six distinct types of elements:</p>
<ul>
<li>context (from which all others are inherrited, and which directly wraps the webaudio AudioContext node)</li>
<li>connectors</li>
<li>audio processing elements</li>
<li>UI elements</li>
<li>automation elements</li>
<li>composed elements</li>
</ul>
<p>The connectors build the connection graph and the only UI they display is a label and a bypass control. They currently include:</p>
<ul>
<li>audio-context</li>
<li>audio-series</li>
<li>audio-parallel</li>
<li>audio-split</li>
<li>audio-merge</li>
<li>audio-feedback</li>
</ul>
<p>The audio processing elements wrap the webaudio nodes which actually do the heavy lifting, as well as provide a UI by which to control the processing. They currently include:</p>
<ul>
<li>audio-player</li>
<li>audio-destination</li>
<li>audio-gain</li>
<li>audio-filter</li>
<li>audio-delay</li>
<li>audio-pan</li>
<li>audio-oscillator</li>
<li>audio-convolver</li>
<li>audio-compressor</li>
</ul>
<p>The UI elements handle UI generation and currently include:</p>
<ul>
<li>ui-number</li>
<li>ui-boolean</li>
<li>ui-list</li>
<li>ui-text</li>
</ul>
<p>The currently implemented automation element is &quot;audio-control&quot;, which modifies specified parameters of it&#39;s parent element based on mathematical functions in the time domain.
The free variable &quot;t&quot; is the current time stored in the webaudio context node which contains the graph.  They also implement several experimental automation techniques:</p>
<ul>
<li>using LFO to automate a webaudio parameter node</li>
<li>random automation based on parameter range and user-specified automation interval </li>
</ul>
<p>Composed elements are ones which leverage other audio-component elements directly. They may use the UI of those elements directly, and/or add some controls of their own. The currently implemented composed elements are:</p>
<ul>
<li>audio-reverb (based on convolver and a set of public domain impulses), and a couple gain elements</li>
<li>audio-equalizer (a graphic equalizer implemented as a set of ten audio-filter elements and some additional UI)</li>
<li>audio-xtc (crosstalk cancelation network implemented mostly in audio-components html)</li>
</ul>
<h2 id="declarative-rather-than-imperative">declarative rather than imperative</h2>
<p>The graph is created declaratively based on the given html; no javascript is required.
We wrap everything inside an audio-context element. This corresponds directly to web audio&#39;s context node.</p>
<p>For instance, here is a simple webaudio graph which takes an audio signal from a file and pipes it through a gain node such that volume can be adjusted, and out to the audio out (typically the computer&#39;s standard audio outs):</p>
<h3 id="javascript-example">Javascript example</h3>
<pre><code>// we assume there is an HTML audio element in the document (our web components create this on the fly in a shadow tree)
var audio = new AudioContext ();
var audioElement = document.querySelector(&quot;#myAudio&quot;);
var player = audio.createMediaElementSource (audioElement);
var gain = audio.createGain();

player.connect (gain)
.connect (audio.destination);
</code></pre><p>The above builds the graph and connects all the nodes, but no UI is present. The author is responsible for adding UI elements to control the gain, and the player (or use built-in browser controls for the player).</p>
<h3 id="html-example">HTML example</h3>
<p>Here is the same graph created via our audio components:</p>
<pre><code>&lt;audio-context&gt;&lt;audio-series&gt;
&lt;audio-player src=&quot;some-file.mp3&quot;&gt;&lt;/audio-player&gt;

&lt;audio-gain label=&quot;master volume&quot;&gt;&lt;/audio-gain&gt;

&lt;audio-destination&gt;&lt;/audio-destination&gt;
&lt;/audio-series&gt;&lt;/audio-context&gt;
</code></pre><p>The player uses the standard browser UI for control (start, stop, seek, volume, etc).
Our web components automatically add UI for specifying audio source file, as well as for controling the gain.
If the <code>label</code> attribute on the gain element were not present, it&#39;s UI would be hidden and it would act as a constant gain whose gain value could be set by a <code>gain</code> attribute.</p>
<h2 id="limitations">Limitations</h2>
<ul>
<li>webaudio can deal with more than 2 channels, but this project assumes all elements either 1 or 2 channels<ul>
<li>webaudio has notion of channels and destinations which are a bit hard to get my head around</li>
<li>generally nodes are stereo in and stereo out, but they can be mono as well depending on channelCount, channelCountMode</li>
<li>filter and delay are explicitly mono, but others can be either depending on what they are connected to</li>
</ul>
</li>
</ul>
<h2 id="all-elements">All elements</h2>
<p>All elements are implemented as web components, and create new HTML elements (known as custom elements in webcomponents parlents). They consist of an html template which generates the UI, and an associated JS class definition.</p>
<p>In the javascript domain, all elements inherrit directly from <code>_AudioContext_</code>.
In the HTML domain, the entire HTML graph needs to be wrapped in a <code>&lt;audio-context&gt; ... &lt;/audio-context&gt;</code> element.</p>
<p>If a label attribute is supplied, they display a UI; if no label is supplied then they stay hidden.
If they have a <code>hide-controls</code> attribute, the value of that attribute is used as a space-separated of field names to hide. Using this, we can display only those fields we need from the element. The <code>audio-reverb</code> element uses this to hide the <code>audio-convolver</code>&#39;s &quot;bypass&quot; control while still displaying the list of available impulses.
Most parameters displayed in the UI can be set in the HTML via attributes.</p>
<h3 id="accessibility">Accessibility</h3>
<p>Each component&#39;s UI lives in its own region (<code>role=&quot;region&quot;</code>) and is labeled via <code>aria-label</code>.
The group label is specified via HTML <code>label</code> attribute on host element.
Because polymer does not encapsulate components completely, IDs still leak out, so we avoid IDref here in favor of <code>aria-label</code>.</p>
<p>We also label the group via span element with <code>role=&quot;heading&quot;</code> and an <code>aria-level</code> corresponding to the nesting level of the host element within the audio context.
This helps navigate the UI and maintain a better sense of location within the hierarchy.
However, we end up with duplicate group label announcement: both the <code>aria-label</code> and the visible group label are seen by the screen reader.</p>
<ul>
<li>if we eliminate the visible label announcement via <code>aria-hidden</code>, we lose the hierarchy info provided by the heading level</li>
<li>if we eliminate the <code>aria-label</code> on the group container, we lose group label announcement on focus (i.e. when tab used to move through the UI) and we lose landmark</li>
</ul>
<p>There seems to be no good solution for this annoyance at present.</p>
<h2 id="processors">Processors</h2>
<p>...</p>
<h2 id="ui-elements">UI Elements</h2>
<p>They generate appropriate input controls (type=&quot;number&quot; for ui-number, type=&quot;text&quot; for ui-text, and type=&quot;checkbox&quot; for ui-boolean). A select element is generated when ui-list is used.
The label attribute specifies a label for the control.
The name attribute specifies a name for the control (generally the name of the current element&#39;s property which is being exposed.
The value attribute pipes the result back to the current element&#39;s property being manipulated.</p>
<p>Numeric controls can also specify min, max, and step, which are passed directly to the underlying html input element.</p>
<h2 id="control-elements">Control Elements</h2>
<p>The audio-control element allows one to specify a parameter to be automated, and a function to generate values based on the current time stored in the underlying webaudio context containing the graph.
The default evaluation intervall is 0.2 seconds.
The parameter must be specified in the markup. The element being controled wraps the <code>audio-controls</code> element; if several parameters of an element are to be automated, the element wraps separate instances of <code>audio-control</code>, one for each parameter being automated.</p>
<p>The automator function can be specified in markup, and also via the UI.
It is a simple javascript expression which is evaluated in the context of the controled element (i.e. the &quot;this&quot; keyword references the currently controled element).
It references the &quot;Math&quot; object using the javascript &quot;with&quot; statement which allows one to reference Math functions via just their name (i.e. sin(t) instead of Math.sin(t)).</p>
<h2 id="connectors">Connectors</h2>
<h3 id="series-connector">Series connector</h3>
<ul>
<li>each child is connected in series to  its siblings, in source order</li>
<li>_in of first child connects to _in of the series</li>
<li>_out of last child connects to _out of the series</li>
</ul>
<h3 id="parallel-connector">Parallel connector</h3>
<ul>
<li>_in of the parallel connector connects to _in of all children</li>
<li>_out of each child connects to _out of the parallel connector</li>
</ul>
<h3 id="feedback">Feedback</h3>
<p>The audio-feedback element sends its input to the input of its single child, and sends the output of it&#39;s child element to the output of the audio-feedback element, as well as sending it back to it&#39;s input, through a gain node. </p>
<h3 id="merge">merge</h3>
<ul>
<li>takes input from previous sibling and merges all its channels into one mono signal</li>
<li>no children</li>
</ul>
<h3 id="split">Split</h3>
<ul>
<li>split must have either 1 or 2 children, currently each of which must be a series
  +if 2 children then first child is connected to left channel of input and second to right channel, and outputs are merged back into a stereo signal at the output of split
  +if 1 child  and no attributes, left of input goes to left of output</li>
<li>the boolean swap-outputs attribute reverses channels on the output<ul>
<li>if 2 children then reverses stereo channels at output</li>
<li>if 1 child then left channel of input goes to right channel of output</li>
</ul>
</li>
<li>the boolean swap-inputs attribute causes channel reversal at the input<ul>
<li>with 2 children, same as swap-outputs</li>
<li>with 1 child, causes right of input to go to left of output</li>
</ul>
</li>
<li>both swap-inputs and swap-outputs on a stereo source with 2 children have no effect<ul>
<li>both attributes on stereo source with 1 child pipes right of input to right of output</li>
</ul>
</li>
</ul>
<h4 id="example-1">Example 1</h4>
<p>Both the oscillator and output gain have UI controls.
The empty series inside split simply passes input to output with unity gain.</p>
<pre><code>&lt;audio-context&gt;&lt;audio-series&gt;
&lt;audio-oscillator label=&quot;my oscillator&quot; frequency=&quot;220.0&quot;&gt;&lt;/audio-oscillator&gt;

&lt;audio-split&gt;&lt;audio-gain&gt;&lt;/audio-gain&gt;&lt;/audio-split&gt;

&lt;audio-gain label=&quot;master volume&quot; gain=&quot;.2&quot;&gt;&lt;/audio-gain&gt;

&lt;audio-destination&gt;&lt;/audio-destination&gt;
&lt;/audio-series&gt;&lt;/audio-context&gt;
</code></pre><h4 id="example-2">Example 2</h4>
<p>Same as above, but puts signal only in right channel at destination.</p>
<pre><code>&lt;audio-context&gt;&lt;audio-series&gt;
&lt;audio-oscillator label=&quot;my oscillator&quot; frequency=&quot;220.0&quot;&gt;&lt;/audio-oscillator&gt;

&lt;audio-split swap-outputs&gt;&lt;audio-gain&gt;&lt;/audio-gain&gt;&lt;/audio-split&gt;

&lt;audio-gain label=&quot;master volume&quot; gain=&quot;.2&quot;&gt;&lt;/audio-gain&gt;

&lt;audio-destination&gt;&lt;/audio-destination&gt;
&lt;/audio-series&gt;&lt;/audio-context&gt;
</code></pre><p>See <code>demo/index.html</code> for a more complex example.</p>
<h2 id="composed-elements">Composed Elements</h2>
<h3 id="-audio-xtc-"><code>audio-xtc</code></h3>
<p>The <code>audio-xtc</code> element wraps a network made from audio-components into a single element.
This is a good mechanism of abstraction, although it does require some development setup and understanding of polymer.
However, following the pattern here can make it fairly simple to develop new elements fairly painlessly.</p>
<h3 id="-audio-equalizer-"><code>audio-equalizer</code></h3>
<p>This implements a graphic equalizer. It uses <code>audio-filter</code>, with type set to &quot;peaking&quot; and all UI controls hidden accept for gain. A reset control is added to quickly reset all bands back to zero gain.</p>
<h3 id="-audio-reverb-"><code>audio-reverb</code></h3>
<p>The audio-reverb element is based on audio-convolver and a public domain impulse library which is distributed with this project.</p>

</body>
</html>
